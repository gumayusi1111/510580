#!/usr/bin/env python3
"""
ETFæ›´æ–°æ¨¡å— - è´Ÿè´£ETFæ•°æ®çš„å¢é‡å’Œå…¨é‡æ›´æ–°
èŒè´£ï¼šå¤„ç†æ•°æ®æ›´æ–°é€»è¾‘ã€æ—¥æœŸèŒƒå›´è®¡ç®—ã€æ•°æ®åˆå¹¶
"""

import os
import pandas as pd
from datetime import datetime, timedelta
from config.settings import get_default_date_range, DATE_FORMAT, FILE_TEMPLATES
from config.settings import BASIC_COLUMNS, RAW_COLUMNS, HFQ_COLUMNS, QFQ_COLUMNS
from .factor_calculator import FactorCalculator
from .logger import get_etf_logger


class ETFUpdater:
    """ETFæ›´æ–°å™¨ - å•ä¸€èŒè´£ï¼šå¤„ç†æ•°æ®æ›´æ–°"""
    
    def __init__(self, api_client, data_processor, auto_calculate_factors=True):
        """åˆå§‹åŒ–æ›´æ–°å™¨"""
        self.client = api_client
        self.processor = data_processor
        self.auto_calculate_factors = auto_calculate_factors
        self.factor_calculator = FactorCalculator() if auto_calculate_factors else None
        self.logger = get_etf_logger()
    
    def calculate_update_range(self, etf_code):
        """è®¡ç®—æ›´æ–°æ—¥æœŸèŒƒå›´"""
        latest_date = self.processor.check_existing_data(etf_code)
        end_date = datetime.now().strftime(DATE_FORMAT)
        
        if latest_date is None:
            # é¦–æ¬¡è·å–å…¨éƒ¨å†å²æ•°æ®
            start_date, _ = get_default_date_range()
            return start_date, end_date, "é¦–æ¬¡è·å–"
        
        # å¢é‡æ›´æ–°ï¼šä»æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹
        latest_dt = datetime.strptime(latest_date, DATE_FORMAT)
        start_dt = latest_dt + timedelta(days=1)
        start_date = start_dt.strftime(DATE_FORMAT)
        
        if start_date > end_date:
            return None, None, "å·²æ˜¯æœ€æ–°"
        
        return start_date, end_date, "å¢é‡æ›´æ–°"
    
    def fetch_and_process_data(self, etf_code, start_date, end_date):
        """è·å–å¹¶å¤„ç†ETFæ•°æ®"""
        print(f"è·å–æ•°æ®: {etf_code} ({start_date} - {end_date})")
        
        # è·å–åŸå§‹æ•°æ®
        adj_data, daily_data = self.client.fetch_etf_data(etf_code, start_date, end_date)
        
        if adj_data is None or daily_data is None or len(daily_data) == 0:
            return None, "æ— æ³•è·å–æ•°æ®æˆ–æ— æ–°æ•°æ®"
        
        # å¤„ç†æ•°æ®
        try:
            merged_data = self.processor.merge_data(daily_data, adj_data)
            merged_data = self.processor.calculate_adjusted_prices(merged_data)
            final_data = self.processor.organize_final_data(merged_data)
            return final_data, f"æˆåŠŸè·å– {len(final_data)} æ¡è®°å½•"
        except Exception as e:
            return None, f"æ•°æ®å¤„ç†å¤±è´¥: {e}"
    
    def update_etf_incremental(self, etf_code):
        """å¢é‡æ›´æ–°ETFæ•°æ®"""
        self.logger.log_operation("INCREMENTAL_UPDATE_START", etf_code, "å¼€å§‹")
        
        start_date, end_date, status = self.calculate_update_range(etf_code)
        
        if start_date is None:
            # æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œä½†ä»æ£€æŸ¥æ˜¯å¦éœ€è¦è®¡ç®—å› å­
            if self.auto_calculate_factors and self.factor_calculator:
                print("ğŸ”„ æ£€æŸ¥å› å­æ›´æ–°éœ€æ±‚...")
                self.factor_calculator.calculate_factors(etf_code, incremental=True)
            self.logger.log_operation("INCREMENTAL_UPDATE_COMPLETE", etf_code, "æ•°æ®å·²æ˜¯æœ€æ–°")
            return True, "æ•°æ®å·²æ˜¯æœ€æ–°"
        
        print(f"{status}: {start_date} - {end_date}")
        
        new_data, message = self.fetch_and_process_data(etf_code, start_date, end_date)
        if new_data is None:
            self.logger.log_operation("INCREMENTAL_UPDATE_FAILED", etf_code, "æ•°æ®è·å–å¤±è´¥", {"error": message})
            return False, message
        
        # è®°å½•æ•°æ®æ›´æ–°è¯¦æƒ…
        update_details = {
            "date_range": f"{start_date} - {end_date}",
            "records_updated": len(new_data)
        }
        self.logger.log_operation("DATA_UPDATE", etf_code, "æˆåŠŸ", update_details)
        
        # åˆå¹¶ä¿å­˜æ•°æ®
        self._merge_and_save(new_data, etf_code)
        
        # è‡ªåŠ¨è®¡ç®—å› å­
        if self.auto_calculate_factors and self.factor_calculator:
            print("\n" + "="*50)
            print("ğŸ§® è‡ªåŠ¨è®¡ç®—æŠ€æœ¯å› å­")
            print("="*50)
            
            factor_start_time = datetime.now()
            factor_success = self.factor_calculator.calculate_factors(etf_code, incremental=True)
            factor_duration = (datetime.now() - factor_start_time).total_seconds()
            
            if factor_success:
                # æ˜¾ç¤ºå› å­æ‘˜è¦
                summary = self.factor_calculator.get_factor_summary(etf_code)
                print(f"\nğŸ“Š å› å­è®¡ç®—æ‘˜è¦:")
                print(f"   ETFä»£ç : {summary['etf_code']}")
                print(f"   å› å­æ–‡ä»¶æ•°: {summary['factor_files']}")
                print(f"   æœ€æ–°æ—¥æœŸ: {summary['latest_date']}")
                print(f"   å¯ç”¨å› å­: {len(summary['available_factors'])} ä¸ª")
                
                # è®°å½•å› å­è®¡ç®—æˆåŠŸ
                self.logger.log_factor_calculation(etf_code, "ALL_FACTORS", "æˆåŠŸ", 
                                                 factor_duration, len(new_data))
                self.logger.log_operation("INCREMENTAL_UPDATE_COMPLETE", etf_code, "æˆåŠŸ", 
                                        {"with_factors": True})
                
                return True, f"å¢é‡æ›´æ–°æˆåŠŸ: {message} + å› å­è®¡ç®—å®Œæˆ"
            else:
                self.logger.log_factor_calculation(etf_code, "ALL_FACTORS", "å¤±è´¥", factor_duration)
                self.logger.log_operation("INCREMENTAL_UPDATE_COMPLETE", etf_code, "éƒ¨åˆ†æˆåŠŸ", 
                                        {"with_factors": False, "factor_error": True})
                return True, f"å¢é‡æ›´æ–°æˆåŠŸ: {message} (å› å­è®¡ç®—å¤±è´¥)"
        
        self.logger.log_operation("INCREMENTAL_UPDATE_COMPLETE", etf_code, "æˆåŠŸ")
        return True, f"å¢é‡æ›´æ–°æˆåŠŸ: {message}"
    
    def update_etf_full(self, etf_code):
        """å…¨é‡æ›´æ–°ETFæ•°æ®"""
        start_date, end_date = get_default_date_range()
        print(f"å…¨é‡æ›´æ–°: {start_date} - {end_date}")
        
        new_data, message = self.fetch_and_process_data(etf_code, start_date, end_date)
        if new_data is None:
            return False, message
        
        # ç›´æ¥ä¿å­˜æ–°æ•°æ®ï¼ˆè¦†ç›–æ—§æ•°æ®ï¼‰
        self.processor.save_separate_files(new_data, etf_code)
        
        # è‡ªåŠ¨è®¡ç®—å› å­ï¼ˆå…¨é‡ï¼‰
        if self.auto_calculate_factors and self.factor_calculator:
            print("\n" + "="*50)
            print("ğŸ§® å…¨é‡è®¡ç®—æŠ€æœ¯å› å­")
            print("="*50)
            
            factor_success = self.factor_calculator.calculate_factors(etf_code, incremental=False)
            if factor_success:
                # æ˜¾ç¤ºå› å­æ‘˜è¦
                summary = self.factor_calculator.get_factor_summary(etf_code)
                print(f"\nğŸ“Š å› å­è®¡ç®—æ‘˜è¦:")
                print(f"   ETFä»£ç : {summary['etf_code']}")
                print(f"   å› å­æ–‡ä»¶æ•°: {summary['factor_files']}")
                print(f"   æœ€æ–°æ—¥æœŸ: {summary['latest_date']}")
                print(f"   å¯ç”¨å› å­: {len(summary['available_factors'])} ä¸ª")
                
                return True, f"å…¨é‡æ›´æ–°æˆåŠŸ: {message} + å› å­è®¡ç®—å®Œæˆ"
            else:
                return True, f"å…¨é‡æ›´æ–°æˆåŠŸ: {message} (å› å­è®¡ç®—å¤±è´¥)"
        
        return True, f"å…¨é‡æ›´æ–°æˆåŠŸ: {message}"
    
    def _merge_and_save(self, new_data, etf_code):
        """åˆå¹¶æ–°æ•°æ®ä¸ç°æœ‰æ•°æ®å¹¶ä¿å­˜"""
        data_sets = {
            "basic": new_data[BASIC_COLUMNS],
            "raw": new_data[RAW_COLUMNS], 
            "hfq": new_data[HFQ_COLUMNS],
            "qfq": new_data[QFQ_COLUMNS],
        }
        
        for data_type, new_df in data_sets.items():
            file_path = self.processor.get_data_file_path(etf_code, FILE_TEMPLATES[data_type])
            
            # ç¡®ä¿æ–°æ•°æ®çš„trade_dateæ˜¯å­—ç¬¦ä¸²ç±»å‹
            new_df = new_df.copy()
            new_df['trade_date'] = new_df['trade_date'].astype(str)
            
            if os.path.exists(file_path):
                # åˆå¹¶ç°æœ‰æ•°æ®
                existing_df = pd.read_csv(file_path)
                # ç¡®ä¿ç°æœ‰æ•°æ®çš„trade_dateä¹Ÿæ˜¯å­—ç¬¦ä¸²ç±»å‹
                existing_df['trade_date'] = existing_df['trade_date'].astype(str)
                
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['trade_date'], keep='last')
                # æ’åºæ—¶ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
                combined_df = combined_df.sort_values('trade_date', ascending=False)
                combined_df.to_csv(file_path, index=False)
            else:
                # ä¿å­˜æ–°æ•°æ®
                new_df.to_csv(file_path, index=False)