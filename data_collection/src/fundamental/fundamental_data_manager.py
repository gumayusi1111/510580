#!/usr/bin/env python3
"""
åŸºæœ¬é¢æ•°æ®ç®¡ç†å™¨
è´Ÿè´£ETFåŸºæœ¬é¢æ•°æ®çš„è·å–ã€æ›´æ–°å’Œç®¡ç†
"""

import os
import pandas as pd
from pathlib import Path
from datetime import datetime
import yaml


class FundamentalDataManager:
    """ETFåŸºæœ¬é¢æ•°æ®ç®¡ç†å™¨"""

    def __init__(self, tushare_client=None):
        """
        åˆå§‹åŒ–åŸºæœ¬é¢æ•°æ®ç®¡ç†å™¨

        Args:
            tushare_client: Tushare APIå®¢æˆ·ç«¯
        """
        self.client = tushare_client
        self.logger = None

        # è·å–é¡¹ç›®æ ¹ç›®å½•å’Œé…ç½®
        script_dir = Path(__file__).parent.parent
        self.project_root = script_dir.parent
        self.factor_data_path = self.project_root / "etf_factor" / "factor_data"

        # åŠ è½½å…¨å±€é…ç½®
        self._load_config()

    def _load_config(self):
        """åŠ è½½å…¨å±€é…ç½®"""
        try:
            config_path = self.project_root / "etf_factor" / "config" / "global.yaml"
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        except Exception as e:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.config = {
                'precision': {
                    'price': 4,
                    'indicator': 4,
                    'percentage': 4,
                    'statistics': 4,
                    'default': 4
                }
            }

    def get_etf_fundamental_data(self, etf_code: str, incremental: bool = True) -> bool:
        """
        è·å–ETFåŸºæœ¬é¢æ•°æ®

        Args:
            etf_code: ETFä»£ç  (å¦‚ '510580.SH')
            incremental: æ˜¯å¦å¢é‡æ›´æ–°

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not self.client:
            print("âŒ Tushareå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return False

        try:
            etf_num = etf_code.replace('.SH', '').replace('.SZ', '')
            fund_dir = self.factor_data_path / "fundamental" / etf_num
            fund_dir.mkdir(parents=True, exist_ok=True)

            print(f"ğŸ“Š è·å– {etf_code} åŸºæœ¬é¢æ•°æ®...")

            success = True

            # 1. è·å–ETFå‡€å€¼æ•°æ®
            if self._get_etf_nav_data(etf_code, fund_dir, incremental):
                print("  âœ… ETFå‡€å€¼æ•°æ®è·å–å®Œæˆ")
            else:
                print("  âš ï¸ ETFå‡€å€¼æ•°æ®è·å–å¤±è´¥")
                success = False

            # 2. è·å–æŒ‡æ•°ä¼°å€¼æ•°æ®
            if self._get_index_valuation_data(etf_code, fund_dir, incremental):
                print("  âœ… æŒ‡æ•°ä¼°å€¼æ•°æ®è·å–å®Œæˆ")
            else:
                print("  âš ï¸ æŒ‡æ•°ä¼°å€¼æ•°æ®è·å–å¤±è´¥")

            # 3. è·å–ETFä»½é¢æ•°æ®
            if self._get_etf_share_data(etf_code, fund_dir, incremental):
                print("  âœ… ETFä»½é¢æ•°æ®è·å–å®Œæˆ")
            else:
                print("  âš ï¸ ETFä»½é¢æ•°æ®è·å–å¤±è´¥")

            # 4. è·å–å®è§‚æ•°æ®ï¼ˆæ‰€æœ‰ETFå…±äº«ï¼‰
            if self._get_macro_data(incremental):
                print("  âœ… å®è§‚æ•°æ®æ›´æ–°å®Œæˆ")
            else:
                print("  âš ï¸ å®è§‚æ•°æ®æ›´æ–°å¤±è´¥")

            return success

        except Exception as e:
            print(f"âŒ è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
            return False

    def _get_etf_nav_data(self, etf_code: str, fund_dir: Path, incremental: bool) -> bool:
        """è·å–ETFå‡€å€¼æ•°æ®"""
        try:
            file_path = fund_dir / "ETF_NAV.csv"

            # ç¡®å®šæŸ¥è¯¢æ—¥æœŸèŒƒå›´
            start_date = "20220101"  # é»˜è®¤èµ·å§‹æ—¥æœŸ
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                if not existing_df.empty:
                    # ä»æœ€æ–°æ—¥æœŸå¼€å§‹å¢é‡æ›´æ–°
                    latest_date = existing_df['trade_date'].max()
                    start_date = str(int(latest_date) + 1)  # ä¸‹ä¸€å¤©å¼€å§‹

            end_date = datetime.now().strftime('%Y%m%d')

            # è°ƒç”¨Tushare APIè·å–å‡€å€¼æ•°æ®
            nav_df = self.client.fund_nav(ts_code=etf_code, start_date=start_date, end_date=end_date)

            if nav_df.empty:
                if incremental:
                    return True  # å¢é‡æ›´æ–°æ—¶æ²¡æœ‰æ–°æ•°æ®æ˜¯æ­£å¸¸çš„
                else:
                    return False

            # è®¡ç®—å› å­
            nav_df = self._calculate_nav_factors(nav_df)

            # åº”ç”¨ç²¾åº¦é…ç½®
            nav_df = self._apply_precision(nav_df, 'nav')

            # æ•°æ®åˆå¹¶å’Œä¿å­˜
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                # åˆå¹¶æ•°æ®ï¼Œå»é‡
                combined_df = pd.concat([existing_df, nav_df], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['ts_code', 'trade_date'], keep='last')
            else:
                combined_df = nav_df

            # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
            combined_df['trade_date'] = combined_df['trade_date'].astype(str)
            combined_df = combined_df.sort_values('trade_date', ascending=False).reset_index(drop=True)

            combined_df.to_csv(file_path, index=False, encoding='utf-8')
            return True

        except Exception as e:
            print(f"  è·å–å‡€å€¼æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def _get_index_valuation_data(self, etf_code: str, fund_dir: Path, incremental: bool) -> bool:
        """è·å–æŒ‡æ•°ä¼°å€¼æ•°æ®"""
        try:
            # ETFå¯¹åº”çš„æŒ‡æ•°ä»£ç æ˜ å°„
            index_mapping = {
                '510300.SH': '000300.SH',  # æ²ªæ·±300
                '510580.SH': '000905.SH',  # ä¸­è¯500
                '513180.SH': 'HSTECH.HI'   # æ’ç”Ÿç§‘æŠ€
            }

            index_code = index_mapping.get(etf_code)
            if not index_code:
                print(f"  æœªæ‰¾åˆ° {etf_code} å¯¹åº”çš„æŒ‡æ•°ä»£ç ")
                return False

            # è·³è¿‡æ— æ³•è·å–çš„æŒ‡æ•°
            if index_code == 'HSTECH.HI':
                print(f"  è·³è¿‡ {index_code} (æš‚ä¸æ”¯æŒ)")
                return True

            file_path = fund_dir / "INDEX_VALUATION.csv"

            # ç¡®å®šæŸ¥è¯¢æ—¥æœŸèŒƒå›´
            start_date = "20220101"
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                if not existing_df.empty:
                    latest_date = existing_df['trade_date'].max()
                    start_date = str(int(latest_date) + 1)

            end_date = datetime.now().strftime('%Y%m%d')

            # è·å–æŒ‡æ•°ä¼°å€¼æ•°æ®
            val_df = self.client.index_dailybasic(ts_code=index_code, start_date=start_date, end_date=end_date)

            if val_df.empty:
                if incremental:
                    return True
                else:
                    return False

            # è®¡ç®—å› å­
            val_df = self._calculate_valuation_factors(val_df)

            # åº”ç”¨ç²¾åº¦é…ç½®
            val_df = self._apply_precision(val_df, 'valuation')

            # æ•°æ®åˆå¹¶å’Œä¿å­˜
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                combined_df = pd.concat([existing_df, val_df], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['ts_code', 'trade_date'], keep='last')
            else:
                combined_df = val_df

            # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
            combined_df['trade_date'] = combined_df['trade_date'].astype(str)
            combined_df = combined_df.sort_values('trade_date', ascending=False).reset_index(drop=True)

            combined_df.to_csv(file_path, index=False, encoding='utf-8')
            return True

        except Exception as e:
            print(f"  è·å–æŒ‡æ•°ä¼°å€¼æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def _get_etf_share_data(self, etf_code: str, fund_dir: Path, incremental: bool) -> bool:
        """è·å–ETFä»½é¢æ•°æ®"""
        try:
            file_path = fund_dir / "ETF_SHARE.csv"

            # ç¡®å®šæŸ¥è¯¢æ—¥æœŸèŒƒå›´
            start_date = "20220101"
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                if not existing_df.empty:
                    latest_date = existing_df['trade_date'].max()
                    start_date = str(int(latest_date) + 1)

            end_date = datetime.now().strftime('%Y%m%d')

            # è·å–åŸºé‡‘ä»½é¢æ•°æ®
            share_df = self.client.fund_share(ts_code=etf_code, start_date=start_date, end_date=end_date)

            if share_df.empty:
                if incremental:
                    return True
                else:
                    return False

            # è®¡ç®—å› å­
            share_df = self._calculate_share_factors(share_df)

            # åº”ç”¨ç²¾åº¦é…ç½®
            share_df = self._apply_precision(share_df, 'share')

            # æ•°æ®åˆå¹¶å’Œä¿å­˜
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                combined_df = pd.concat([existing_df, share_df], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['ts_code', 'trade_date'], keep='last')
            else:
                combined_df = share_df

            # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
            combined_df['trade_date'] = combined_df['trade_date'].astype(str)
            combined_df = combined_df.sort_values('trade_date', ascending=False).reset_index(drop=True)

            combined_df.to_csv(file_path, index=False, encoding='utf-8')
            return True

        except Exception as e:
            print(f"  è·å–ä»½é¢æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def _get_macro_data(self, incremental: bool) -> bool:
        """è·å–å®è§‚æ•°æ®"""
        try:
            macro_dir = self.factor_data_path / "macro"
            macro_dir.mkdir(parents=True, exist_ok=True)
            file_path = macro_dir / "SHIBOR_RATES.csv"

            # ç¡®å®šæŸ¥è¯¢æ—¥æœŸèŒƒå›´
            start_date = "20231001"  # SHIBORæ•°æ®ç›¸å¯¹è¾ƒæ–°
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                if not existing_df.empty:
                    latest_date = existing_df['trade_date'].max()
                    start_date = str(int(latest_date) + 1)

            end_date = datetime.now().strftime('%Y%m%d')

            # è·å–SHIBORåˆ©ç‡æ•°æ®
            shibor_df = self.client.shibor(start_date=start_date, end_date=end_date)

            if shibor_df.empty:
                if incremental:
                    return True
                else:
                    return False

            # é‡å‘½ååˆ—
            if 'date' in shibor_df.columns:
                shibor_df.rename(columns={'date': 'trade_date'}, inplace=True)

            # åº”ç”¨ç²¾åº¦é…ç½®
            shibor_df = self._apply_precision(shibor_df, 'macro')

            # æ•°æ®åˆå¹¶å’Œä¿å­˜
            if incremental and file_path.exists():
                existing_df = pd.read_csv(file_path)
                combined_df = pd.concat([existing_df, shibor_df], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['trade_date'], keep='last')
            else:
                combined_df = shibor_df

            # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
            combined_df['trade_date'] = combined_df['trade_date'].astype(str)
            combined_df = combined_df.sort_values('trade_date', ascending=False).reset_index(drop=True)

            combined_df.to_csv(file_path, index=False, encoding='utf-8')
            return True

        except Exception as e:
            print(f"  è·å–å®è§‚æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def _calculate_nav_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—å‡€å€¼ç›¸å…³å› å­"""
        if df.empty:
            return df

        df = df.copy()
        df = df.sort_values('trade_date').reset_index(drop=True)

        # å‡€å€¼æ”¶ç›Šç‡
        df['NAV_RETURN'] = df['adj_nav'].pct_change()

        # å‡€å€¼ç§»åŠ¨å¹³å‡
        df['NAV_MA_5'] = df['adj_nav'].rolling(window=5).mean()
        df['NAV_MA_20'] = df['adj_nav'].rolling(window=20).mean()

        # å‡€å€¼æ³¢åŠ¨ç‡
        df['NAV_STD_20'] = df['NAV_RETURN'].rolling(window=20).std()

        return df

    def _calculate_valuation_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ä¼°å€¼ç›¸å…³å› å­"""
        if df.empty:
            return df

        df = df.copy()
        df = df.sort_values('trade_date').reset_index(drop=True)

        # PE/PBç™¾åˆ†ä½æ•°ï¼ˆéœ€è¦å†å²æ•°æ®è®¡ç®—ï¼‰
        df['PE_PERCENTILE'] = df['pe'].rolling(window=252, min_periods=30).rank(pct=True)
        df['PB_PERCENTILE'] = df['pb'].rolling(window=252, min_periods=30).rank(pct=True)

        # PE/PBç§»åŠ¨å¹³å‡
        df['PE_MA_20'] = df['pe'].rolling(window=20).mean()
        df['PB_MA_20'] = df['pb'].rolling(window=20).mean()

        return df

    def _calculate_share_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ä»½é¢ç›¸å…³å› å­"""
        if df.empty:
            return df

        df = df.copy()
        df = df.sort_values('trade_date').reset_index(drop=True)

        # ä»½é¢å˜åŒ–
        df['SHARE_CHANGE'] = df['fd_share'].diff()
        df['SHARE_CHANGE_PCT'] = df['fd_share'].pct_change()

        # ä»½é¢ç§»åŠ¨å¹³å‡
        df['SHARE_MA_5'] = df['fd_share'].rolling(window=5).mean()

        return df

    def _apply_precision(self, df: pd.DataFrame, data_type: str) -> pd.DataFrame:
        """åº”ç”¨ç²¾åº¦é…ç½®"""
        if df.empty:
            return df

        precision = self.config['precision']

        if data_type == 'nav':
            # å‡€å€¼æ•°æ®ç²¾åº¦
            price_cols = ['unit_nav', 'accum_nav', 'accum_div', 'net_asset', 'total_netasset', 'adj_nav']
            for col in price_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['price'])

            factor_cols = ['NAV_RETURN', 'NAV_MA_5', 'NAV_MA_20', 'NAV_STD_20']
            for col in factor_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['indicator'])

        elif data_type == 'valuation':
            # ä¼°å€¼æ•°æ®ç²¾åº¦
            valuation_cols = ['pe', 'pb', 'pe_ttm', 'pb_mrq']
            for col in valuation_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['indicator'])

            ratio_cols = ['turnover_rate', 'volume_ratio']
            for col in ratio_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['percentage'])

            percentile_cols = ['PE_PERCENTILE', 'PB_PERCENTILE']
            for col in percentile_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['statistics'])

            ma_cols = ['PE_MA_20', 'PB_MA_20']
            for col in ma_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['indicator'])

        elif data_type == 'share':
            # ä»½é¢æ•°æ®ç²¾åº¦
            share_cols = ['fd_share']
            for col in share_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['default'])

            change_cols = ['SHARE_CHANGE', 'SHARE_CHANGE_PCT']
            for col in change_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['percentage'])

            ma_cols = ['SHARE_MA_5']
            for col in ma_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['default'])

        elif data_type == 'macro':
            # å®è§‚æ•°æ®ç²¾åº¦
            rate_cols = ['1m', '3m', '6m', '9m', '1y', '2w', '1w', 'on']
            for col in rate_cols:
                if col in df.columns:
                    df[col] = df[col].round(precision['percentage'])

        return df

    def cleanup_fundamental_data(self, etf_code: str) -> bool:
        """æ¸…ç†ETFåŸºæœ¬é¢æ•°æ®"""
        try:
            etf_num = etf_code.replace('.SH', '').replace('.SZ', '')
            fund_dir = self.factor_data_path / "fundamental" / etf_num

            if fund_dir.exists():
                import shutil
                shutil.rmtree(fund_dir)
                print(f"âœ… å·²åˆ é™¤åŸºæœ¬é¢æ•°æ®: {fund_dir}")
                return True
            else:
                print(f"âš ï¸ åŸºæœ¬é¢æ•°æ®ç›®å½•ä¸å­˜åœ¨: {fund_dir}")
                return True

        except Exception as e:
            print(f"âŒ æ¸…ç†åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
            return False

    def get_fundamental_summary(self, etf_code: str) -> dict:
        """è·å–åŸºæœ¬é¢æ•°æ®æ‘˜è¦"""
        try:
            etf_num = etf_code.replace('.SH', '').replace('.SZ', '')
            fund_dir = self.factor_data_path / "fundamental" / etf_num

            summary = {
                'etf_code': etf_code,
                'fundamental_files': 0,
                'latest_date': 'N/A',
                'available_data': []
            }

            if not fund_dir.exists():
                return summary

            # ç»Ÿè®¡æ–‡ä»¶
            csv_files = list(fund_dir.glob("*.csv"))
            summary['fundamental_files'] = len(csv_files)

            # è·å–å¯ç”¨æ•°æ®ç±»å‹å’Œæœ€æ–°æ—¥æœŸ
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    if not df.empty and 'trade_date' in df.columns:
                        latest_date = str(df['trade_date'].max())
                        summary['available_data'].append({
                            'type': csv_file.stem,
                            'records': len(df),
                            'latest_date': latest_date
                        })

                        # æ›´æ–°æ€»ä½“æœ€æ–°æ—¥æœŸ
                        if summary['latest_date'] == 'N/A' or latest_date > summary['latest_date']:
                            summary['latest_date'] = latest_date
                except Exception:
                    continue

            return summary

        except Exception as e:
            print(f"âŒ è·å–åŸºæœ¬é¢æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return {
                'etf_code': etf_code,
                'fundamental_files': 0,
                'latest_date': 'N/A',
                'available_data': []
            }