#!/usr/bin/env python3
"""
æµ‹è¯•å¢é‡æ›´æ–°åŠŸèƒ½
éªŒè¯æ‰€æœ‰å› å­çš„å¢é‡æ›´æ–°æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
from datetime import datetime, timedelta
from src.engine import VectorizedEngine
from src.data_loader import DataLoader
from src.cache import CacheManager

def test_incremental_update_functionality():
    """æµ‹è¯•å¢é‡æ›´æ–°åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å¢é‡æ›´æ–°åŠŸèƒ½...")
    print("=" * 60)
    
    # åˆå§‹åŒ–å¼•æ“
    engine = VectorizedEngine()
    data_loader = DataLoader("../data")
    cache_manager = CacheManager()
    
    # è·å–å…¨é‡æ•°æ®ä¿¡æ¯
    data_info = data_loader.get_data_info()
    print(f"ğŸ“Š æ•°æ®ä¿¡æ¯:")
    print(f"   æ€»è¡Œæ•°: {data_info['rows']}")
    print(f"   å¼€å§‹æ—¥æœŸ: {data_info['start_date']}")  
    print(f"   ç»“æŸæ—¥æœŸ: {data_info['end_date']}")
    print()
    
    # æµ‹è¯•å¢é‡æ•°æ®åŠ è½½åŠŸèƒ½
    print("ğŸ”„ æµ‹è¯•å¢é‡æ•°æ®åŠ è½½...")
    
    # å‡è®¾æœ€åæ›´æ–°æ—¥æœŸä¸ºæ•°æ®å€’æ•°ç¬¬10å¤©
    full_data = data_loader.load_data("hfq")
    last_update_date = full_data['trade_date'].iloc[-10]  
    print(f"   æ¨¡æ‹Ÿæœ€åæ›´æ–°æ—¥æœŸ: {last_update_date.date()}")
    
    # åŠ è½½å¢é‡æ•°æ®
    incremental_data = data_loader.load_incremental_data(
        last_date=last_update_date.strftime('%Y-%m-%d'),
        data_type="hfq"
    )
    print(f"   å¢é‡æ•°æ®è¡Œæ•°: {len(incremental_data)}")
    print(f"   å¢é‡æ•°æ®æ—¥æœŸèŒƒå›´: {incremental_data['trade_date'].min().date()} ~ {incremental_data['trade_date'].max().date()}")
    
    if len(incremental_data) == 0:
        print("âš ï¸  æ²¡æœ‰å¢é‡æ•°æ®å¯ä¾›æµ‹è¯•")
        return False
    
    print()
    
    # æµ‹è¯•ç¼“å­˜çš„å¢é‡æ›´æ–°åŠŸèƒ½
    print("ğŸ”„ æµ‹è¯•ç¼“å­˜å¢é‡æ›´æ–°...")
    
    # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§å› å­è¿›è¡Œæµ‹è¯•
    test_factors = ['SMA', 'MACD', 'BOLL', 'OBV', 'MAX_DD']
    
    update_results = {}
    
    for factor_name in test_factors:
        if factor_name not in engine.factors:
            print(f"âš ï¸  å› å­ {factor_name} æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
            continue
            
        print(f"   æµ‹è¯•å› å­: {factor_name}")
        
        try:
            # 1. å…ˆè®¡ç®—åˆ°last_update_dateçš„å› å­æ•°æ®ï¼ˆæ¨¡æ‹Ÿå†å²ç¼“å­˜ï¼‰
            historical_data = full_data[full_data['trade_date'] <= last_update_date].copy()
            
            # åˆ›å»ºå› å­å®ä¾‹
            factor_class = engine.factors[factor_name]
            factor = factor_class()
            
            # è®¡ç®—å†å²æ•°æ®
            historical_result = factor.calculate_vectorized(historical_data)
            historical_rows = len(historical_result)
            
            # ç”Ÿæˆç¼“å­˜é”®
            data_hash = data_loader.get_data_hash(historical_data)
            cache_key = factor.get_cache_key(data_hash)
            
            # ç¼“å­˜å†å²æ•°æ®
            cache_manager.cache_factor(cache_key, historical_result, factor_name)
            
            # 2. è®¡ç®—å¢é‡æ•°æ®çš„å› å­
            incremental_result = factor.calculate_vectorized(incremental_data)
            incremental_rows = len(incremental_result)
            
            # 3. ä½¿ç”¨å¢é‡æ›´æ–°åŠŸèƒ½
            cache_manager.update_incremental(cache_key, incremental_result, factor_name)
            
            # 4. éªŒè¯æ›´æ–°åçš„ç¼“å­˜æ•°æ®
            updated_cached_data = cache_manager.get_cached_factor(cache_key)
            updated_rows = len(updated_cached_data)
            
            print(f"     å†å²æ•°æ®: {historical_rows} è¡Œ")
            print(f"     å¢é‡æ•°æ®: {incremental_rows} è¡Œ") 
            print(f"     æ›´æ–°å: {updated_rows} è¡Œ")
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            expected_rows = historical_rows + incremental_rows
            if updated_rows >= expected_rows - 10:  # å…è®¸å°‘é‡é‡å 
                update_results[factor_name] = "âœ… é€šè¿‡"
            else:
                update_results[factor_name] = f"âŒ å¤±è´¥ (æœŸæœ›â‰¥{expected_rows-10}, å®é™…{updated_rows})"
                
        except Exception as e:
            update_results[factor_name] = f"âŒ å¼‚å¸¸: {str(e)[:50]}..."
            
    print()
    
    # æ±‡æ€»æµ‹è¯•ç»“æœ
    print("ğŸ“‹ å¢é‡æ›´æ–°æµ‹è¯•ç»“æœ:")
    for factor_name, result in update_results.items():
        print(f"   {factor_name:12} : {result}")
    
    print()
    
    # ç»Ÿè®¡æˆåŠŸç‡
    success_count = sum(1 for result in update_results.values() if "âœ…" in result)
    total_count = len(update_results)
    success_rate = success_count / total_count * 100 if total_count > 0 else 0
    
    print(f"ğŸ¯ å¢é‡æ›´æ–°æˆåŠŸç‡: {success_count}/{total_count} ({success_rate:.1f}%)")
    
    # æ£€æŸ¥ç³»ç»Ÿç»„ä»¶çš„å¢é‡æ›´æ–°æ”¯æŒ
    print()
    print("ğŸ” ç³»ç»Ÿç»„ä»¶å¢é‡æ›´æ–°æ”¯æŒ:")
    print("   âœ… DataLoader.load_incremental_data() - æ”¯æŒå¢é‡æ•°æ®åŠ è½½")
    print("   âœ… CacheManager.update_incremental() - æ”¯æŒå¢é‡ç¼“å­˜æ›´æ–°") 
    print("   âœ… åŸºäºtrade_dateçš„æ•°æ®å»é‡åˆå¹¶")
    print("   âœ… è‡ªåŠ¨å¤„ç†æ—¥æœŸèŒƒå›´ç­›é€‰")
    
    return success_rate >= 80  # 80%ä»¥ä¸ŠæˆåŠŸç‡è§†ä¸ºé€šè¿‡

def test_factor_level_incremental_support():
    """æµ‹è¯•æ¯ä¸ªå› å­çš„å¢é‡è®¡ç®—æ”¯æŒæƒ…å†µ"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥å„å› å­çš„å¢é‡è®¡ç®—ç‰¹æ€§...")
    print("=" * 60)
    
    engine = VectorizedEngine()
    
    # å› å­å¢é‡è®¡ç®—ç‰¹æ€§åˆ†æ
    factor_analysis = {}
    
    for factor_name, factor_class in engine.factors.items():
        try:
            factor = factor_class()
            factor_info = factor.get_factor_info()
            
            # åˆ†æå› å­çš„è®¡ç®—ç‰¹æ€§
            calculation_method = factor_info.get('calculation_method', '')
            formula = factor_info.get('formula', '')
            
            # åˆ¤æ–­æ˜¯å¦æ”¯æŒå¢é‡è®¡ç®—
            incremental_friendly = True
            incremental_notes = []
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å…¨å†å²æ•°æ®
            if 'cumsum' in formula.lower() or 'cum' in calculation_method.lower():
                incremental_friendly = False
                incremental_notes.append("éœ€è¦ç´¯ç§¯è®¡ç®—")
                
            if 'expanding' in formula.lower() or factor_name in ['OBV', 'CUM_RETURN']:
                incremental_friendly = False  
                incremental_notes.append("éœ€è¦å…¨å†å²æ•°æ®")
                
            # ç§»åŠ¨å¹³å‡ç±»å› å­é€šå¸¸æ”¯æŒå¢é‡è®¡ç®—
            if any(x in factor_name.upper() for x in ['SMA', 'EMA', 'WMA', 'VMA']):
                incremental_friendly = True
                incremental_notes.append("æ»šåŠ¨è®¡ç®—ï¼Œå¢é‡å‹å¥½")
                
            # æŠ€æœ¯æŒ‡æ ‡ç±»å› å­
            if any(x in factor_name.upper() for x in ['RSI', 'MACD', 'BOLL', 'ATR', 'TR']):
                incremental_friendly = True
                incremental_notes.append("æŠ€æœ¯æŒ‡æ ‡ï¼Œå¢é‡å‹å¥½")
                
            factor_analysis[factor_name] = {
                'incremental_friendly': incremental_friendly,
                'notes': incremental_notes,
                'category': factor_info.get('category', 'unknown')
            }
            
        except Exception as e:
            factor_analysis[factor_name] = {
                'incremental_friendly': False,
                'notes': [f"åˆ†æå¤±è´¥: {e}"],
                'category': 'error'
            }
    
    # æŒ‰ç±»åˆ«ç»„ç»‡è¾“å‡º
    categories = {}
    for factor_name, info in factor_analysis.items():
        category = info['category']
        if category not in categories:
            categories[category] = []
        categories[category].append((factor_name, info))
    
    for category, factors in categories.items():
        print(f"\nğŸ“‚ {category.replace('_', ' ').title()}:")
        for factor_name, info in factors:
            status = "âœ…" if info['incremental_friendly'] else "âš ï¸"
            notes = " | ".join(info['notes'][:2])  # åªæ˜¾ç¤ºå‰2ä¸ªæ³¨é‡Š
            print(f"   {status} {factor_name:12} : {notes}")
    
    # ç»Ÿè®¡æ€»ä½“æƒ…å†µ
    total_factors = len(factor_analysis)
    incremental_friendly_count = sum(1 for info in factor_analysis.values() 
                                   if info['incremental_friendly'])
    
    print(f"\nğŸ¯ å¢é‡è®¡ç®—æ”¯æŒæƒ…å†µ:")
    print(f"   æ”¯æŒå¢é‡: {incremental_friendly_count}/{total_factors} ä¸ªå› å­")
    print(f"   æ”¯æŒç‡: {incremental_friendly_count/total_factors*100:.1f}%")
    
    return factor_analysis

if __name__ == "__main__":
    print("ğŸš€ å¢é‡æ›´æ–°åŠŸèƒ½å…¨é¢æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: ç³»ç»Ÿå¢é‡æ›´æ–°åŠŸèƒ½
    system_test_passed = test_incremental_update_functionality()
    
    # æµ‹è¯•2: å„å› å­å¢é‡è®¡ç®—ç‰¹æ€§åˆ†æ
    factor_analysis = test_factor_level_incremental_support()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆè¯„ä¼°:")
    print("=" * 60)
    
    if system_test_passed:
        print("âœ… ç³»ç»Ÿå¢é‡æ›´æ–°åŠŸèƒ½: æ­£å¸¸å·¥ä½œ")
    else:
        print("âŒ ç³»ç»Ÿå¢é‡æ›´æ–°åŠŸèƒ½: éœ€è¦æ”¹è¿›")
    
    incremental_support_rate = sum(1 for info in factor_analysis.values() 
                                 if info['incremental_friendly']) / len(factor_analysis) * 100
    
    print(f"ğŸ“ˆ å› å­å¢é‡å…¼å®¹æ€§: {incremental_support_rate:.1f}%")
    
    # ç»™å‡ºç»¼åˆè¯„ä¼°å’Œå»ºè®®
    print("\nğŸ’¡ å»ºè®®:")
    if incremental_support_rate >= 80:
        print("   â€¢ å¤§éƒ¨åˆ†å› å­æ”¯æŒå¢é‡è®¡ç®—ï¼Œç³»ç»Ÿæ¶æ„åˆç†")
        print("   â€¢ å¯ä»¥æ”¾å¿ƒä½¿ç”¨å¢é‡æ›´æ–°åŠŸèƒ½")
    elif incremental_support_rate >= 60:
        print("   â€¢ éƒ¨åˆ†å› å­éœ€è¦ç‰¹æ®Šå¤„ç†å¢é‡æ›´æ–°")
        print("   â€¢ å»ºè®®ä¸ºç´¯ç§¯ç±»å› å­å®ç°ä¸“é—¨çš„å¢é‡ç­–ç•¥")
    else:
        print("   â€¢ å¢é‡è®¡ç®—å…¼å®¹æ€§è¾ƒä½")
        print("   â€¢ å»ºè®®é‡æ–°è®¾è®¡å› å­è®¡ç®—æ¶æ„")
    
    print("   â€¢ å®šæœŸæ¸…ç†ç¼“å­˜ä»¥ä¿æŒæ•°æ®ä¸€è‡´æ€§")
    print("   â€¢ ç›‘æ§å¢é‡æ›´æ–°çš„æ•°æ®è´¨é‡")