#!/usr/bin/env python3
"""
ETFå®Œæ•´æ•°æ®è·å–è„šæœ¬ - 510580.SH ä¸­è¯500ETFæ˜“æ–¹è¾¾
è·å–åŸºé‡‘æ—¥çº¿æ•°æ®ã€å¤æƒå› å­ï¼Œå¹¶è®¡ç®—å‰å¤æƒå’Œåå¤æƒä»·æ ¼
"""

import os
import sys
import traceback
from datetime import datetime, timedelta
import pandas as pd
import tushare as ts  # cspell:ignore tushare


def setup_tushare_token():  # cspell:ignore tushare
    """è®¾ç½®tushare token"""  # cspell:ignore tushare
    # TODO: è¯·åœ¨è¿™é‡Œè®¾ç½®ä½ çš„tushare token  # cspell:ignore tushare
    token = "d27a688495ac9b1eef8534011f5d39282fb516d71095c2e976d6b1f7"
    if not token or token == "your_token_here":
        print("é”™è¯¯: è¯·å…ˆåœ¨è„šæœ¬ä¸­è®¾ç½®æœ‰æ•ˆçš„tushare token")  # cspell:ignore tushare
        sys.exit(1)

    ts.set_token(token)
    return ts.pro_api()


def get_data_file_path(filename):
    """è·å–æ•°æ®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    data_dir = os.path.join(project_dir, "data")

    # ç¡®ä¿dataç›®å½•å­˜åœ¨
    os.makedirs(data_dir, exist_ok=True)

    return os.path.join(data_dir, filename)


def fetch_etf_data(pro, etf_code, start_date, end_date):
    """è·å–ETFåŸºé‡‘æ•°æ®å’Œå¤æƒå› å­"""
    print(f"è·å– {etf_code} æ•°æ®...")
    print(f"æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")

    try:
        # è·å–åŸºé‡‘å¤æƒå› å­
        print("\n1. è·å–åŸºé‡‘å¤æƒå› å­...")
        adj_data = pro.fund_adj(
            ts_code=etf_code, start_date=start_date, end_date=end_date
        )
        print(f"è·å–åˆ° {len(adj_data)} æ¡å¤æƒå› å­æ•°æ®")

        if len(adj_data) == 0:
            print("è­¦å‘Š: æœªè·å–åˆ°å¤æƒå› å­æ•°æ®")
            return None, None

        # è·å–åŸºé‡‘æ—¥çº¿æ•°æ®
        print("\n2. è·å–åŸºé‡‘æ—¥çº¿æ•°æ®...")
        daily_data = pro.fund_daily(
            ts_code=etf_code, start_date=start_date, end_date=end_date
        )
        print(f"è·å–åˆ° {len(daily_data)} æ¡æ—¥çº¿æ•°æ®")

        if len(daily_data) == 0:
            print("è­¦å‘Š: æœªè·å–åˆ°æ—¥çº¿æ•°æ®")
            return adj_data, None

        return adj_data, daily_data

    except Exception as e:
        print(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
        traceback.print_exc()
        return None, None


def calculate_adjusted_prices(merged_data):
    """è®¡ç®—å‰å¤æƒå’Œåå¤æƒä»·æ ¼"""
    print("\n3. è®¡ç®—å¤æƒä»·æ ¼...")

    # è·å–æœ€æ–°å¤æƒå› å­ï¼ˆç”¨äºå‰å¤æƒè®¡ç®—ï¼‰
    latest_adj_factor = merged_data.iloc[0]["adj_factor"]
    print(f"æœ€æ–°å¤æƒå› å­: {latest_adj_factor}")

    # åå¤æƒè®¡ç®—: ä»·æ ¼ Ã— å½“æ—¥å¤æƒå› å­
    merged_data["hfq_open"] = merged_data["open"] * merged_data["adj_factor"]
    merged_data["hfq_high"] = merged_data["high"] * merged_data["adj_factor"]
    merged_data["hfq_low"] = merged_data["low"] * merged_data["adj_factor"]
    merged_data["hfq_close"] = merged_data["close"] * merged_data["adj_factor"]

    # å‰å¤æƒè®¡ç®—: ä»·æ ¼ Ã· æœ€æ–°å¤æƒå› å­
    merged_data["qfq_open"] = merged_data["open"] / latest_adj_factor
    merged_data["qfq_high"] = merged_data["high"] / latest_adj_factor
    merged_data["qfq_low"] = merged_data["low"] / latest_adj_factor
    merged_data["qfq_close"] = merged_data["close"] / latest_adj_factor

    print("å¤æƒä»·æ ¼è®¡ç®—å®Œæˆ")
    print("- hfq_*: åå¤æƒä»·æ ¼ (ä»·æ ¼ Ã— å½“æ—¥å¤æƒå› å­)")
    print("- qfq_*: å‰å¤æƒä»·æ ¼ (ä»·æ ¼ Ã· æœ€æ–°å¤æƒå› å­)")

    return merged_data


def organize_final_data(merged_data):
    """æ•´ç†æœ€ç»ˆæ•°æ®åˆ—é¡ºåº"""
    column_order = [
        # åŸºç¡€ä¿¡æ¯
        "ts_code",
        "trade_date",
        # åŸå§‹ä»·æ ¼æ•°æ®
        "pre_close",
        "open",
        "high",
        "low",
        "close",
        "change",
        "pct_chg",
        "vol",
        "amount",
        # å¤æƒå› å­
        "adj_factor",
        # åå¤æƒä»·æ ¼
        "hfq_open",
        "hfq_high",
        "hfq_low",
        "hfq_close",
        # å‰å¤æƒä»·æ ¼
        "qfq_open",
        "qfq_high",
        "qfq_low",
        "qfq_close",
    ]

    return merged_data[column_order]


def save_separate_files(merged_data, etf_code):
    """ä¿å­˜4ä¸ªç‹¬ç«‹çš„æ•°æ®æ–‡ä»¶"""
    code_name = etf_code.replace(".", "_")

    print("\n=== ç”Ÿæˆ4ä¸ªä¸“é—¨æ•°æ®æ–‡ä»¶ ===")

    # 1. åŸºç¡€æ•°æ®æ–‡ä»¶ï¼ˆåŒ…å«å¤æƒå› å­ï¼Œç”¨äºè®¡ç®—ï¼‰
    basic_cols = [
        "ts_code",
        "trade_date",
        "pre_close",
        "open",
        "high",
        "low",
        "close",
        "change",
        "pct_chg",
        "vol",
        "amount",
        "adj_factor",
    ]
    basic_data = merged_data[basic_cols]
    basic_file = get_data_file_path(f"{code_name}_basic_data.csv")
    basic_data.to_csv(basic_file, index=False)
    print(f"âœ… åŸºç¡€æ•°æ®: {basic_file}")

    # 2. é™¤æƒæ•°æ®æ–‡ä»¶ï¼ˆåŸå§‹äº¤æ˜“æ•°æ®ï¼Œæ— å¤æƒè°ƒæ•´ï¼‰
    raw_cols = [
        "ts_code",
        "trade_date",
        "pre_close",
        "open",
        "high",
        "low",
        "close",
        "change",
        "pct_chg",
        "vol",
        "amount",
    ]
    raw_data = merged_data[raw_cols]
    raw_file = get_data_file_path(f"{code_name}_raw_data.csv")
    raw_data.to_csv(raw_file, index=False)
    print(f"âœ… é™¤æƒæ•°æ®: {raw_file}")

    # 3. åå¤æƒæ•°æ®æ–‡ä»¶ï¼ˆç”¨äºé‡åŒ–å›æµ‹ï¼‰
    hfq_cols = [
        "ts_code",
        "trade_date",
        "hfq_open",
        "hfq_high",
        "hfq_low",
        "hfq_close",
        "vol",
        "amount",
    ]
    hfq_data = merged_data[hfq_cols]
    hfq_file = get_data_file_path(f"{code_name}_hfq_data.csv")
    hfq_data.to_csv(hfq_file, index=False)
    print(f"âœ… åå¤æƒæ•°æ®: {hfq_file}")

    # 4. å‰å¤æƒæ•°æ®æ–‡ä»¶ï¼ˆç”¨äºå½“å‰ä»·ä½åˆ†æï¼‰
    qfq_cols = [
        "ts_code",
        "trade_date",
        "qfq_open",
        "qfq_high",
        "qfq_low",
        "qfq_close",
        "vol",
        "amount",
    ]
    qfq_data = merged_data[qfq_cols]
    qfq_file = get_data_file_path(f"{code_name}_qfq_data.csv")
    qfq_data.to_csv(qfq_file, index=False)
    print(f"âœ… å‰å¤æƒæ•°æ®: {qfq_file}")

    return basic_data, raw_data, hfq_data, qfq_data


def show_data_summary(merged_data):
    """æ˜¾ç¤ºæ•°æ®æ±‡æ€»ä¿¡æ¯"""
    print("\n=== æ•°æ®æ¦‚è§ˆ ===")
    print(f"è®°å½•æ•°: {len(merged_data)}")
    print(
        f"æ—¶é—´èŒƒå›´: {merged_data['trade_date'].min()} åˆ° {merged_data['trade_date'].max()}"
    )

    # æ˜¾ç¤ºå¤æƒå› å­ç»Ÿè®¡
    unique_factors = merged_data["adj_factor"].unique()
    print(f"å¤æƒå› å­èŒƒå›´: {unique_factors.min():.3f} - {unique_factors.max():.3f}")
    print(f"å¤æƒå› å­å”¯ä¸€å€¼æ•°é‡: {len(unique_factors)}")

    # æ˜¾ç¤ºæ ·ä¾‹æ•°æ®å¯¹æ¯”
    print("\n=== ä»·æ ¼å¯¹æ¯”æ ·ä¾‹ (æœ€è¿‘3å¤©) ===")
    sample_data = merged_data.head(3)
    for _, row in sample_data.iterrows():
        print(f"\næ—¥æœŸ: {row['trade_date']}")
        print(f"  é™¤æƒæ”¶ç›˜: {row['close']:.3f}")
        print(f"  åå¤æƒæ”¶ç›˜: {row['hfq_close']:.3f} (Ã—{row['adj_factor']:.2f})")
        print(f"  å‰å¤æƒæ”¶ç›˜: {row['qfq_close']:.3f} (Ã·{row['adj_factor']:.2f})")

    print("\n=== æ–‡ä»¶ç”¨é€”è¯´æ˜ ===")
    print("ğŸ“Š basic_data.csv   - åŸºç¡€æ•°æ® + å¤æƒå› å­ï¼ˆå®Œæ•´ä¿¡æ¯ï¼‰")
    print("ğŸ“ˆ raw_data.csv     - é™¤æƒæ•°æ®ï¼ˆåŸå§‹äº¤æ˜“ä»·æ ¼ï¼‰")
    print("ğŸ¯ hfq_data.csv     - åå¤æƒæ•°æ®ï¼ˆé‡åŒ–å›æµ‹æ¨èï¼‰")
    print("ğŸ’¡ qfq_data.csv     - å‰å¤æƒæ•°æ®ï¼ˆå½“å‰ä»·ä½åˆ†æï¼‰")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("ETFå®Œæ•´æ•°æ®è·å–è„šæœ¬")
    print("=" * 50)

    # é…ç½®å‚æ•°
    etf_code = "510580.SH"  # ä¸­è¯500ETFæ˜“æ–¹è¾¾
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=7 * 365)).strftime("%Y%m%d")

    try:
        # 1. è®¾ç½®tushare
        pro = setup_tushare_token()

        # 2. è·å–æ•°æ®
        adj_data, daily_data = fetch_etf_data(pro, etf_code, start_date, end_date)

        if adj_data is None or daily_data is None:
            print("é”™è¯¯: æ— æ³•è·å–å¿…è¦æ•°æ®")
            sys.exit(1)

        # 3. åˆå¹¶æ•°æ®
        print("\nåˆå¹¶æ•°æ®...")
        merged_data = pd.merge(
            daily_data, adj_data, on=["ts_code", "trade_date"], how="inner"
        )
        print(f"åˆå¹¶åæ•°æ®è¡Œæ•°: {len(merged_data)}")

        # 4. è®¡ç®—å¤æƒä»·æ ¼
        merged_data = calculate_adjusted_prices(merged_data)

        # 5. æ•´ç†æ•°æ®æ ¼å¼
        final_data = organize_final_data(merged_data)

        # 6. ä¿å­˜4ä¸ªç‹¬ç«‹æ•°æ®æ–‡ä»¶
        save_separate_files(final_data, etf_code)

        # 7. æ˜¾ç¤ºæ•°æ®æ±‡æ€»
        show_data_summary(final_data)

        print("\nâœ… æ•°æ®è·å–å®Œæˆ!")

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
